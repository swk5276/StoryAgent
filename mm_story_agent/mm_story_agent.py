import time
import json
from pathlib import Path
import sys
from networkx import full_rary_tree
import torch.multiprocessing as mp
mp.set_start_method("spawn", force=True)
import ast
from tqdm import tqdm
from tqdm import trange
from .base import init_tool_instance

class MMStoryAgent:

    def __init__(self) -> None:
        # ì‚¬ìš©í•  ëª¨ë‹¬ë¦¬í‹° ëª©ë¡ ì§€ì • ("speech", "music")
        self.modalities = ["image","speech", "music"]

    def call_modality_agent(self, modality, agent, params, return_dict):
        # ì—ì´ì „íŠ¸ì˜ call ë©”ì„œë“œë¡œ ê²°ê³¼ ìƒì„±
        result = agent.call(params)
        # ê²°ê³¼ë¥¼ ê³µìœ  ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
        return_dict[modality] = result
    
    def generate_modality_assets(self, config, scene_summaries, scene_metadatas):
        story_dir = Path(config["story_dir"])
        for sub_dir in self.modalities:
            (story_dir / sub_dir).mkdir(exist_ok=True, parents=True)

        agents = {}
        params = {}
        processes = []
        return_dict = mp.Manager().dict()

        for modality in self.modalities:
            agents[modality] = init_tool_instance(config[modality + "_generation"])
            
            # ëª¨ë‹¬ë¦¬í‹°ë³„ë¡œ í˜ì´ì§€ ì†ŒìŠ¤ ë‹¤ë¥´ê²Œ ì„ íƒ
            if modality == "image":
                page_data = scene_metadatas
            else:
                page_data = scene_summaries

            params[modality] = config[modality + "_generation"]["params"].copy()

            params[modality].update({
                "pages": page_data,
                "save_path": story_dir / modality
            })

            p = mp.Process(
                target=self.call_modality_agent,
                args=(modality, agents[modality], params[modality], return_dict)
            )
            processes.append(p)
            p.start()

        for p in processes:
            p.join()

        print("ëª¨ë‹¬ë¦¬í‹°ë³„ ìì‚° ìƒì„± ì™„ë£Œ.")

    def compose_storytelling_video(self, config, scene_summaries, scene_metadatas, use_metadata_for_video=False):
        # ë¹„ë””ì˜¤ í•©ì„±ìš© ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        video_compose_agent = init_tool_instance(config["video_compose"])

        # í˜ì´ì§€ ë°ì´í„° ì„ íƒ
        pages = scene_metadatas if use_metadata_for_video else scene_summaries

        # íŒŒë¼ë¯¸í„° ë³µì‚¬ í›„ í˜ì´ì§€ ì •ë³´ ì¶”ê°€
        params = config["video_compose"]["params"].copy()
        params["pages"] = pages

        # ë¹„ë””ì˜¤ í•©ì„± ì‹¤í–‰
        video_compose_agent.call(params)

    # total 
    def call(self, config):

        # íŒŒì¼ ê²½ë¡œ ê°ì²´
        story_dir = Path(config["story_dir"])

        # Whisper text in params
        raw_text = config["story_writer"]["params"]["full_context"]

        with open(story_dir / "full_text_raw.txt", "w", encoding="utf-8") as f:
            f.write(raw_text)


        # Refine writer [ full_text_raw => full_text ]
        refine_writer = init_tool_instance(config["refine_writer"])
        full_text = refine_writer.call({"raw_text": raw_text})

        with open(story_dir / "full_text.txt", "w", encoding="utf-8") as f:
            f.write(full_text)


        # Scene extractor [ full_text => scene_text ]
        scene_extractor = init_tool_instance(config["scene_extractor"])
        scene_list = scene_extractor.call({"full_text": full_text})

        with open(story_dir / "scene_text.json", "w", encoding="utf-8") as f:
            json.dump({"scenes": scene_list}, f, indent=4, ensure_ascii=False)


        # Scene narration & scripter [ scene_text => scene_summaries ]
        summary_writer = init_tool_instance(config["summary_writer"])
        scene_summaries = []

        meta_writer = init_tool_instance(config["meta_writer"])
        scene_metadatas = []

        print("Sceneë³„ ëŒ€ë³¸, ë©”íƒ€, ë“±ì¥ì¸ë¬¼ ìƒì„± ì¤‘...")


        for idx, scene in enumerate(tqdm(scene_list, desc="Generating summary/metadata per scene")):

            try:
                raw_summary = summary_writer.call({"scene_text": scene})  # ë¬¸ìì—´ í˜•íƒœì˜ JSONì´ ì˜¬ ìˆ˜ ìˆìŒ

                try:
                    parsed = json.loads(raw_summary)  # ë¬¸ìì—´ -> dict
                    summary = parsed["scenes"][0]["summary"]  # summaryë§Œ ì¶”ì¶œ
                except Exception:
                    summary = raw_summary  # JSON êµ¬ì¡°ê°€ ì•„ë‹ˆë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥

            except Exception as e:
                summary = f"[Error generating summary]: {e}"

            scene_summaries.append(summary)
            # try:
            #     summary = summary_writer.call({"scene_text": scene})
            # except Exception as e:
            #     summary = f"[Error generating summary]: {e}"
            # scene_summaries.append(summary)

            try:
                metadata = meta_writer.call({"scene_text": scene})
            except Exception as e:
                metadata = f"[Error generating metadata]: {e}"
            scene_metadatas.append(metadata)

        # Saving summary & metadata 
        with open(story_dir / "scene_summaries.json", "w", encoding="utf-8") as f:
            json.dump(scene_summaries, f, ensure_ascii=False, indent=2)

        with open(story_dir / "scene_metadatas.json", "w", encoding="utf-8") as f:
            json.dump(scene_metadatas, f, ensure_ascii=False, indent=2)

        print("Text-to-Scene pipeline completed.")

        return
    
        # Generating modality
        print("Generating modality assets...")
        pages = [s for s in scene_summaries]  # ìš”ì•½ ê²°ê³¼ë¥¼ ê° í˜ì´ì§€ storyë¡œ í™œìš©
        self.generate_modality_assets(config, scene_summaries, scene_metadatas)
        # 5. ë¹„ë””ì˜¤ í•©ì„±
        print("ğŸ¬ Composing storytelling video...")
        self.compose_storytelling_video(
            config,
            scene_summaries=scene_summaries,
            scene_metadatas=scene_metadatas,
            use_metadata_for_video=False  # â† í•„ìš” ì‹œ Trueë¡œ ë³€ê²½
        )

