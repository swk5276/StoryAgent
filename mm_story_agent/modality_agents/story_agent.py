# JSON ë°ì´í„° ì²˜ë¦¬ìš© ëª¨ë“ˆ
import json
# íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ ëª¨ë“ˆ
from typing import Dict
# ë¬´ì‘ìœ„ ìˆ˜ ìƒì„±ì„ ìœ„í•œ ëª¨ë“ˆ
import random
# tqdm: ë°˜ë³µë¬¸ì˜ ì§„í–‰ ìƒí™©ì„ ë³´ì—¬ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
from tqdm import trange, tqdm

# LLM ì¶œë ¥ ê²°ê³¼ë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
from ..utils.llm_output_check import parse_list
# ë„êµ¬ ë“±ë¡ ë° ì´ˆê¸°í™” í•¨ìˆ˜
from ..base import register_tool, init_tool_instance
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë“¤ ë¶ˆëŸ¬ì˜¤ê¸°
from ..prompts_en2 import question_asker_system, expert_system, \
    dlg_based_writer_system, dlg_based_writer_prompt, chapter_writer_system

# JSON í˜•íƒœì˜ outlineì´ ìœ íš¨í•œì§€ ê²€ì‚¬í•˜ëŠ” í•¨ìˆ˜
def json_parse_outline(outline):
    # ì½”ë“œ ë¸”ë¡ ë§ˆí¬ë‹¤ìš´(```json ë“±)ì„ ì œê±°
    outline = outline.strip("```json").strip("```")
    try:
        # ë¬¸ìì—´ì„ JSONìœ¼ë¡œ íŒŒì‹±
        outline = json.loads(outline)
        # ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
        if not isinstance(outline, dict):
            return False
        # í•„ìš”í•œ í‚¤ë§Œ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if outline.keys() != {"story_title", "story_outline"}:
            return False
        # ê° ì±•í„°ê°€ í•„ìš”í•œ í‚¤ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸
        for chapter in outline["story_outline"]:
            if chapter.keys() != {"chapter_title", "chapter_summary"}:
                return False
    except json.decoder.JSONDecodeError:
        # JSON íŒŒì‹± ì‹¤íŒ¨
        return False
    return True  # ëª¨ë“  ì¡°ê±´ í†µê³¼ ì‹œ True ë°˜í™˜

# ì§ˆë¬¸ ìƒì„± LLM ê³¼ ì „ë¬¸ê°€ ì—­í•  LLMì„ í†µí•´ Q & A ëŒ€í™” ìƒì„± 
@register_tool("qa_outline_story_writer")
class QAOutlineStoryWriter:

    # í´ë˜ìŠ¤ ìƒì„±ì
    def __init__(self, cfg: Dict):
        self.cfg = cfg
        # LLM ìƒì„± ì˜¨ë„ ì„¤ì • (ê¸°ë³¸ê°’ 1.0)
        self.temperature = cfg.get("temperature", 1.0)
        # ëŒ€í™” ìµœëŒ€ í„´ ìˆ˜ ì„¤ì •
        self.max_conv_turns = cfg.get("max_conv_turns", 3)
        # ìƒì„±í•  ì•„ì›ƒë¼ì¸ ê°œìˆ˜ ì„¤ì •
        self.num_outline = cfg.get("num_outline", 4)
        # ì‚¬ìš©í•  LLM ì¢…ë¥˜ ì„¤ì •
        self.llm_type = cfg.get("llm", "qwen")

    # ëŒ€í™” ê¸°ë°˜ ì•„ì›ƒë¼ì¸ì„ JSON í˜•íƒœë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    def generate_outline(self, params):
        # params: ì´ì•¼ê¸° ì„¤ì • ì •ë³´ (ì˜ˆ: ì œëª©, ì£¼ì¸ê³µ ë“±)

        # ì§ˆë¬¸ ìƒì„±ìš© LLM ì´ˆê¸°í™”
        asker = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": question_asker_system,
                "track_history": False
            }
        })

        # ì „ë¬¸ê°€ ì—­í•  LLM ì´ˆê¸°í™”
        expert = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": expert_system,
                "track_history": False
            }
        })

        # ì§ˆë¬¸-ë‹µë³€ ê¸°ë¡ ì €ì¥ ë¦¬ìŠ¤íŠ¸
        dialogue = []
        for turn in trange(self.max_conv_turns):  # ìµœëŒ€ ì§€ì •ëœ íšŸìˆ˜ë§Œí¼ ë°˜ë³µ
            dialogue_history = "\n".join(dialogue)  # í˜„ì¬ê¹Œì§€ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê²°í•©

            # ë³€ê²½
            full_context = params.get("full_context", str(params))
            # ì§ˆë¬¸ ìƒì„±
            question, success = asker.call(
                f"Story setting: {full_context}\nDialogue history: \n{dialogue_history}\n",
                temperature=self.temperature
            )
            question = question.strip()

            # 'ëŒ€í™” ì¢…ë£Œ' ë¬¸êµ¬ê°€ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
            if question == "Thank you for your help!":
                break

            # ì§ˆë¬¸ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
            dialogue.append(f"You: {question}")

            # ì „ë¬¸ê°€ì˜ ë‹µë³€ ìƒì„±
            answer, success = expert.call(
                f"Story setting: {full_context}\nQuestion: \n{question}\nAnswer: ",
                temperature=self.temperature
            )
            answer = answer.strip()
            dialogue.append(f"Expert: {answer}")

        # ì•„ì›ƒë¼ì¸ ì‘ì„±ê¸° LLM ì´ˆê¸°í™”
        writer = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": dlg_based_writer_system,
                "track_history": False
            }
        })
        # full_context ê°€ì ¸ì˜¤ê¸°
        full_context = params.get("full_context", "")
        # ì•„ì›ƒë¼ì¸ ì‘ì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        writer_prompt = dlg_based_writer_prompt.format(
            story_setting=full_context,
            dialogue_history="\n".join(dialogue),
            num_outline=self.num_outline
        )

        # ì•„ì›ƒë¼ì¸ ìƒì„± ì‹œë„
        outline, success = writer.call(writer_prompt, success_check_fn=json_parse_outline)

        # ë””ë²„ê¹…ìš© ì¶œë ¥
        try:
            preview_outline = outline.replace("```json", "").replace("```", "").strip()
            parsed_outline = json.loads(preview_outline)
            print("ğŸ” [DEBUG] Parsed Outline:")
            print(json.dumps(parsed_outline, ensure_ascii=False, indent=4))
        except Exception as e:
            print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì¶œë ¥:")
            print(repr(outline))
        # ìœ íš¨í•˜ì§€ ì•Šì€ ê²°ê³¼ì¸ ê²½ìš° ì—ëŸ¬ ë°œìƒ
        if not outline or not outline.strip():
            raise ValueError(f"LLMì—ì„œ ìœ íš¨í•œ outlineì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {repr(outline)}")

        # ë§ˆí¬ë‹¤ìš´ JSON ë¸”ë¡ ì œê±°
        outline = outline.replace("```json", "").replace("```", "").strip()

        # JSON íŒŒì‹±
        outline = json.loads(outline)

        # ìµœì¢… outline ë°˜í™˜
        return outline

    # ì•„ì›ƒë¼ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì±•í„°ë³„ ìƒì„¸ ì´ì•¼ê¸° ìƒì„±
    def generate_story_from_outline(self, outline):
        # ì±•í„° ì‘ì„±ìš© LLM ì´ˆê¸°í™”
        chapter_writer = init_tool_instance({
            "tool": self.llm_type,
            "cfg": {
                "system_prompt": chapter_writer_system,
                "track_history": False
            }
        })

        all_pages = []  # ì „ì²´ ì´ì•¼ê¸° í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
        for idx, chapter in enumerate(tqdm(outline["story_outline"])):
            # í˜„ì¬ê¹Œì§€ì˜ ë‚´ìš©ê³¼ ìƒˆë¡œìš´ ì±•í„° ì •ë³´ë¥¼ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
            chapter_detail, success = chapter_writer.call(
                json.dumps(
                    {
                        "completed_story": all_pages,
                        "current_chapter": chapter
                    },
                    ensure_ascii=False
                ),
                success_check_fn=parse_list,  # ì¶œë ¥ì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ì§€ í™•ì¸
                temperature=self.temperature
            )

            # ì‹¤íŒ¨í•œ ê²½ìš° ì‹œë“œ ëœë¤ê°’ ì£¼ì–´ ì¬ì‹œë„
            while success is False:
                chapter_detail, success = chapter_writer.call(
                    json.dumps(
                        {
                            "completed_story": all_pages,
                            "current_chapter": chapter
                        },
                        ensure_ascii=False
                    ),
                    seed=random.randint(0, 100000),  # ì‹œë“œ ë³€ê²½
                    temperature=self.temperature,
                    success_check_fn=parse_list
                )

            # ë¬¸ìì—´ë¡œ ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ íŒŒì‹± (eval ì‚¬ìš©)
            pages = [page.strip() for page in eval(chapter_detail)]
            all_pages.extend(pages)  # ì „ì²´ í˜ì´ì§€ì— ì¶”ê°€

        # ëª¨ë“  í˜ì´ì§€ ë°˜í™˜
        return all_pages

    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
    def call(self, params):
        # 1ë‹¨ê³„: ì•„ì›ƒë¼ì¸ ìƒì„±
        outline = self.generate_outline(params)
        # 2ë‹¨ê³„: ì•„ì›ƒë¼ì¸ ê¸°ë°˜ ì±•í„°ë³„ ì´ì•¼ê¸° ìƒì„±
        pages = self.generate_story_from_outline(outline)
        # ìµœì¢… í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return pages
