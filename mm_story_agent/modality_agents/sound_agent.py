# íŒŒì¼ ê²½ë¡œ ë° íƒ€ì… íŒíŠ¸ë¥¼ ìœ„í•œ ëª¨ë“ˆ
from pathlib import Path
from typing import List, Dict
import json

# ì˜¤ë””ì˜¤ ì €ì¥ ë° ëª¨ë¸ ë¡œë”©ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch
import soundfile as sf
from diffusers import AudioLDM2Pipeline

# í”„ë¡¬í”„íŠ¸ì™€ ë„êµ¬ ë“±ë¡ ìœ í‹¸
from mm_story_agent.prompts_en import story_to_sound_reviser_system, story_to_sound_review_system
from mm_story_agent.base import register_tool, init_tool_instance

# ì˜¤ë””ì˜¤ ìƒì„±ê¸°ë¥¼ êµ¬í˜„ í´ë˜ìŠ¤
class AudioLDM2Synthesizer:

    def __init__(self,
                 device: str = 'cuda'  # GPU ì‚¬ìš© ê¶Œì¥
                 ) -> None:
        self.device = device
        # Hugging Faceì˜ AudioLDM2 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        self.pipe = AudioLDM2Pipeline.from_pretrained(
            "cvssp/audioldm2",
            torch_dtype=torch.float16  # FP16ë¡œ ì†ë„/ë©”ëª¨ë¦¬ ìµœì í™”
        ).to(self.device)

    # ğŸ§ íš¨ê³¼ìŒ ìƒì„± í•¨ìˆ˜
    def call(self,
             prompts: List[str],              # ì˜¤ë””ì˜¤ ìƒì„±ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ ëª©ë¡
             n_candidate_per_text: int = 3,   # í”„ë¡¬í”„íŠ¸ë‹¹ ìƒì„±í•  ì˜¤ë””ì˜¤ ìˆ˜
             seed: int = 0,                   # ëœë¤ ì‹œë“œ ê³ ì •
             guidance_scale: float = 3.5,     # í…ìŠ¤íŠ¸ ì¡°ê±´ ë°˜ì˜ ê°•ë„
             ddim_steps: int = 100            # ë””í“¨ì „ ë‹¨ê³„ ìˆ˜
             ):
        # ì‹œë“œ ê³ ì •ìš© ìƒì„±ê¸°
        generator = torch.Generator(device=self.device).manual_seed(seed)

        # ì˜¤ë””ì˜¤ ìƒì„±
        audios = self.pipe(
            prompts=prompts,
            num_inference_steps=ddim_steps,
            audio_length_in_s=10.0,
            guidance_scale=guidance_scale,
            generator=generator,
            num_waveforms_per_prompt=n_candidate_per_text
        ).audios

        # ê° í”„ë¡¬í”„íŠ¸ë‹¹ ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ë§Œ ì„ íƒ
        audios = audios[::n_candidate_per_text]
        return audios

# ì‚¬ìš´ë“œ ì—ì´ì „íŠ¸ ë“±ë¡: "audioldm2_t2a" (text-to-audio)
@register_tool("audioldm2_t2a")
class AudioLDM2Agent:

    def __init__(self, cfg) -> None:
        self.cfg = cfg  # êµ¬ì„± ì„¤ì • ì €ì¥

    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
    def call(self, params: Dict):
        pages: List = params["pages"]         # ì´ì•¼ê¸° í˜ì´ì§€ ëª©ë¡
        save_path: str = params["save_path"]  # ì˜¤ë””ì˜¤ ì €ì¥ ê²½ë¡œ

        # 1. ì´ì•¼ê¸°ë¡œë¶€í„° íš¨ê³¼ìŒ ì„¤ëª… ìƒì„±
        sound_prompts = self.generate_sound_prompt_from_story(pages)

        # 2. ì˜¤ë””ì˜¤ë¡œ ìƒì„±í•  í”„ë¡¬í”„íŠ¸ë§Œ ì¶”ë¦¼
        save_paths = []
        forward_prompts = []
        save_path = Path(save_path)  # ë¬¸ìì—´ â†’ Path ê°ì²´
        for idx in range(len(pages)):
            if sound_prompts[idx] != "No sounds.":  # íš¨ê³¼ìŒ í•„ìš” ì—†ëŠ” ê²½ìš° ì œì™¸
                save_paths.append(save_path / f"p{idx + 1}.wav")  # ê° í˜ì´ì§€ ë³„ íŒŒì¼ëª…
                forward_prompts.append(sound_prompts[idx])

        # 3. ì˜¤ë””ì˜¤ ìƒì„±ê¸° ì´ˆê¸°í™”
        generation_agent = AudioLDM2Synthesizer(
            device=self.cfg.get("device", "cuda")
        )

        # 4. ì‹¤ì œ ì˜¤ë””ì˜¤ ìƒì„± ë° ì €ì¥
        if len(forward_prompts) > 0:
            sounds = generation_agent.call(
                forward_prompts,
                n_candidate_per_text=params.get("n_candidate_per_text", 3),
                seed=params.get("seed", 0),
                guidance_scale=params.get("guidance_scale", 3.5),
                ddim_steps=params.get("ddim_steps", 100),
            )
            for sound, path in zip(sounds, save_paths):
                # ìƒì„±ëœ ì˜¤ë””ì˜¤ë¥¼ wav íŒŒì¼ë¡œ ì €ì¥
                sf.write(path.__str__(), sound, self.cfg["sample_rate"])

        # ê²°ê³¼ë¡œ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ëª©ë¡ ë°˜í™˜
        return {
            "prompts": sound_prompts,
        }

    # ğŸ“˜ ìŠ¤í† ë¦¬ë¡œë¶€í„° íš¨ê³¼ìŒ ì„¤ëª… í”„ë¡¬í”„íŠ¸ ìƒì„±
    def generate_sound_prompt_from_story(
            self,
            pages: List,  # ê° í˜ì´ì§€ëŠ” í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸
        ):
        # ì„¤ëª… ìƒì„± LLM ì´ˆê¸°í™”
        sound_prompt_reviser = init_tool_instance({
            "tool": self.cfg.get("llm", "qwen"),
            "cfg": {
                "system_prompt": story_to_sound_reviser_system,
                "track_history": False
            }
        })

        # ì„¤ëª… ê²€í†  LLM ì´ˆê¸°í™”
        sound_prompt_reviewer = init_tool_instance({
            "tool": self.cfg.get("llm", "qwen"),
            "cfg": {
                "system_prompt": story_to_sound_review_system,
                "track_history": False
            }
        })

        num_turns = self.cfg.get("num_turns", 3)  # ë°˜ë³µ íšŸìˆ˜ ì œí•œ
        sound_prompts = []

        # í˜ì´ì§€ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        for page in pages:
            review = ""
            sound_prompt = ""

            # ê°œì„  ë°˜ë³µ
            for turn in range(num_turns):
                # 1. ì„¤ëª… ìƒì„±
                sound_prompt, success = sound_prompt_reviser.call(json.dumps({
                    "story": page,
                    "previous_result": sound_prompt,
                    "improvement_suggestions": review,
                }, ensure_ascii=False))

                # "Sound description:" ì ‘ë‘ì–´ ì œê±°
                if sound_prompt.startswith("Sound description:"):
                    sound_prompt = sound_prompt[len("Sound description:"):]

                # 2. ì„¤ëª… ê²€í† 
                review, success = sound_prompt_reviewer.call(json.dumps({
                    "story": page,
                    "sound_description": sound_prompt
                }, ensure_ascii=False))

                # í†µê³¼í•˜ë©´ ë°˜ë³µ ì¢…ë£Œ
                if review == "Check passed.":
                    break

            # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì €ì¥
            sound_prompts.append(sound_prompt)

        return sound_prompts
